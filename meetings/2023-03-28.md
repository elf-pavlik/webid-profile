# W3C Solid Community Group: WebID Profile

* Date: 2023-03-28T16:00:00Z
* Call: <https://meet.jit.si/solid-profile>
* Chat: <https://gitter.im/solid/webid-profile>
* Repository: <https://github.com/solid/webid-profile>

## Present

* [Virginia Balseiro](https://virginiabalseiro.com/#me)
* [Sarven Capadisli](https://csarven.ca/#i)
* Timea Turdean
* Eric Jahn

---

## Announcements

### Meeting Recordings and Transcripts

* No audio or video recording, or automated transcripts without consent. Meetings are transcribed and made public. If consent is withheld by anyone, recording/retention must not occur.
* Join queue to talk.

### Participation and Code of Conduct

* [Solid Code of Conduct](https://github.com/solid/process/blob/main/code-of-conduct.md), [Positive Work Environment at W3C: Code of Ethics and Professional Conduct](https://www.w3.org/Consortium/cepc/)
* Operating principle for effective participation is to allow access across disabilities, across country borders, and across time. Feedback on tooling and meeting timing is welcome.
* If this is your first time, welcome! please introduce yourself.

### Scribes

* Virginia

---

## Introductions

* name

## Topics

### Conformance and testing

* VB: Proposed by SC
* TT: We can do this topic in the context of TI.
* VB: Both TI and WebID-Profile.
* SC: I created an issue about conformance in TI.
* TT: Yeah. Very generic though.
* SC: It's something we should walk through using these two specs as example. I'll screenshare and talk over what's there, then we can jump to TI and WebID-Profile as to how you'd express similar things.
* SC: We have Notifications Protocol and Solid Protocol. (screen-shares).
* SC: See also <https://solidproject.org/ED/qa>
* SC: We have this QA document for Solid. We outline policy around WA. We want to talk about how TRs are expressed, what test suites will do, how test cases are expressed (in RDF), how we assess the tests and how we report them. This is important because in the end we will have these specs where there will a link to implementation reports and test suites, because we want implementors not just reading specs but running stuff through tests and have a report that everything is implemented correctly. When you click on those implementation reports there will be a report document with all implementations (screen: table showing implementation report of different implementations). There's a checkbox where each requirement links to the spec. Example: dokieli conforms to the sender role in this report, so all the requirements in specification having something to do with sender, dokieli is tested against that. We have the tests results linking back to the spec, to the requirement reported. To show something has matured in QA we link to reports showing implementations are passing those tests. Part of that is what TRs should look like: we want to express all significant things in the reports. Significant things are individual requirements, each conformance clause - server MUST advertise Link Header, etc. It has a subject (server) and the expectations. What would be successful/failure. When we have a spec requirement, for example in Solid protocol, "server MUST conform to xyz", that is one clear requirement.
* VB: How this applies to TypeIndex - or like webID profile where we have very few MUSTS, it is very loose - How can we apply this to it?
* SC: good question. We need to figure out how we express this parts. Let's go back.
* SC: The part we have to figure out is how to express normative and informative content. When we use these keywords, that is a normative requirement. And then there's other types of thing that are mostly advisory. In your spec, it will be setting rules as how to read this spec. You need to be clear about the language. You already have some of that in there but there's more to it.
* SC: In Solid protocol we have two things generally being tested/have requirements for: servers and clients. These requirements have those as subjects. I nNotifications we have other types of things: subscription clients (software that is a subscription client has to follow certain rules). So some conformance clauses in the spec are specific to subscription client. What is the thing that needs to implement these requirements so it can be conforming/testable/interoperable? In Notifications we have 5 things that can be implemented. You could have one implementation doing one of these things and it'll be passing these tests. Interoperability is when you have a combination of things that need to communicate in order for the spec to consider that there is something interoperable. In this case we say: subscription client is tested by checking their ability to request... ??? once we have these individual products following these reqs, qwe check that a client can talk to any server, then we say it is interoperable. Back to Solid protocol, we have interoperability between servers and clients.
* SC: Back to Solid WebID-Profile: You need to define what are the type of things that is supposed to be implementable and what needs to talk to each other. What things in the spec do you want to be testable/considered to be a product/implementable? We can say, is storage a thing that needs to be implementable? Client needs to create a TI, it needs to store it somewhere, should spec have requirements for a storage/resource server accepting TI? This in particular in based on Solid protocol, so we know this is already well defined so that saves us additional requirements because this TI spec is not adding additional requirements on storage. If you get an implementation that implements server from Solid protocol, out of the box that's usable for WebID-Profile/TI.
* SC: what about other things: is application something that needs implementing? Interoperability: does application need to interact with server? The spec already says that and that is type of products that could be mentioned in conformance section. You can say "app MUST interact with Solid server/storage", and so on.  
* SC: I will now complicate things even further. W3C has this document on variability of specs: <https://www.w3.org/TR/spec-variability/>
* SC: There's nothing here above and beyond new to Solid. It's been around for decades. In Solid we are following those rules/expectations and adding new things to that,things to do with for example how machine-readable a spec can be, etc. For now you don't need to go into making spec be RDF. At some point in your spec you need to have, when you wruite a comformance clause, you want it to be clear to the reader that that requirement has a subject and a requirement level and what tose are. Once you start doing that you need to link to things/definitions. When you do that you are one step away from expressing it as an RDF requirement. This document is machine readable, each req in this spec is in RDF. Here's a requirement (screen sharing: dereferencing the spec/requirement). It says the spec has a requirement and the req has a URI, and the req has a subject, and the req is about a subscription client, there is a req level (MUST), and there's a human readable description of the req. Essentially: subject, statement. I'm saying all of this because when you express all these significant units: the subjects/things that a dev might want to implement, if an app dev comes to TI it is clean, but what if a server dev comes and wonders if there's a requirement for them to implement. They will know that right away from looking at classes of product. If there's nothing about the server, then the server dev does not to do anything.
* SC: another exmaple: not just servers/client, you can have other classes of products. Other concepts maybe like a processor, or a producer, or content. What this group needs to do is to figure out what that implementation is. Is it the shape? Is application being tested, shape, processor.. for example, should there be a req saying "broken RDF should be rejected", "a profile that doesn;'t match this shape should be rejected", you can say that. Not necessariliy the server determining if it conforms to the shape, but you could say it, and have a new specific product called a processor. Someone can implement just a processor where its only job is for server to send payload to processor and processor checks vocabs, shapes, etc. You could say "processor is a thing that should be testable". Look beyond server/client but other types of expressing what those things are. That's what Solid QA is trying to do: starting by expressing those things. When you look at a test report, this product (example) is called a sender. We have sender, consumer, receiver. That's one of the things being tested and the report will show a test for that particular thing: can it discover inbox, etc. These are not things you need to worry about in the spec, but the work that you're doing is going to be involved in testing. Starts with first having a humane readable thing about these things/units of information. And then the reqs are other significant parts of the spec. When you clearly write them out and link to them... you're 80% there. Adding the RDF is just the last bit that ties up everything.
* TT: Step back to testing: for example TI. I have an implemntation of TI in SolidOS, and in order to prove that it is an implementation, it would have to provide the technical report that it conforms to the test, whatever the test is defined to be based on the requirements clearly defined as RDF. Do I need to provide for the TI TR to prove that SolidOs is an implementation?
* SC: IT does not need to be part of it. In spec you don't mention any particular implementation. You just provide a link to a document with a list of implementations. Linking to a doc that has all these implementation reports, you don't need to call it an application. If you think that thing is interoperable thing consuming TI, just reads, you can say this. This is an implementable ting called "consumer" and another one could be "TI writer" or something. You need to think through some terms that would best express.
* TT: I need at least a dopcument with these examples linked to the entities/products we have, but not necessarily going into details of checkboxes/reports. I can put the checkboxes and people can trust me, but behind that checkbox is a software/test harness that is run to check for example to validate TIs, that they conform to shape, etc.
* SC: Exactly. The test suite and implementation reports... you don't need to develop that, these are things that you can put in place to show that it's adoptable/mature. The closer you get to that the better. Anyone can claim a spec exists, but in the wild, can SolidOS work with any server (re: TI)? and so on. To ensure that app can pass these tests. So you have the test suite that can look like this: list of tests, instructions on how you can test that.
* TT: Could be manual.
* SC: It could be manual. The test suite will incorporate... For example EARL, test suite incorporates something like this where ther eis an assertion, the subject... based on some criterion based on the test, has a result, and mode: can be manual, automated, semi-auto, and that's how you can describe the test.
* TT: How do I go about keeping track of versions of these implmenetations? With any software you test on particular version, so that needs to be part of that report...
* SC: In the Solid QA document we are still working through what reports should look like, what test cases are, etc. Example: here's a req linking to the thing in th spec, was this test reviewed/approved? what was input/expected result, who contributed, etc? You don't need to develop a test suite software. what's important is working with the test suite team to see how you can express/create tests using that test suite software. So you can only focused on...
* TT: Are you saying our tests should be integrated in the existing test suites?
* SC: You're welcome to write tests. But maybe work with the test suite team to see how much of that work you can offload. Maybe you only need to write the logic... if the request includes content-type text/turtle, and it's POST/PUT whatever to create a TI, you can focus on just the logic of "if it meets these things, result should be whatever".
* TT: So for example, for both our specs, you take the shape and you run it through any sort of RDF validator tool, and you apply the shape to see if your data is valid or not. So that's like semi-auto way of having a basis to describe at least one test.
* SC: Things fall into place when you take some time, once you nail this down the rest of the spec falls into place. Define the concepts, think about what needs to be interoperable, take time... takes a lot of revision to come uop with these terms (app? consumer? creator?). You don't need to come up with 50 different things, just find a balance. Is a processor for the request a thing? Solid protocol is now just server and client.
* SC: I wrote this issue about server/client, but we could consider furhter specifying. We already say storage is a thing, processor could be a thing. One example of a processor is maybe something like, when you do a write request and you want to do a patch update, you send a payload with ??? and we expect the rules to be something that is processing the ??? payload. If we had time and no objections, in that particular specs we could extract the processor as an implementable thing: someone can implement a resource server, and have another piece of software only implementing the N3 patch processing. We don't wanna end up with one giant software doing everything. Then people could contribute to Solid by writing an app reading a profile, creating a TI, and so on. If we break it down, it means different people/codebases can implement different parts. It's important for interop/extensibility/evolution of this work to say we have different software implementing different parts. Whatever you decide is not right/wrong, just find a balance where you expect ??? You can run. ahackathon and say "today we're implementing a TI cretor app.. reqs are 5 of these reqs on the spec." Once you can identify those it can be more easily implemented.
* VB: I am going to think about this stuff for WebId-Profile and Timea maybe you can think about TypeIndex. And we can continue next time after doing this homework.
* SC: if you do this exercise you can write any spec because you have the foundations there. A lot of this is based off <https://www.w3.org/DesignIssues/Axioms.html#Universality2>
* SC: Anything of significant should be given a URI. Looking at this document, what is significant here? There are many different signficant things here you can try to given a URI. That's where RDF comes in. To approach that you just need to start with a terminology section, some things linked to other terms, and then in conformance section you're linking to server/client, etc. Similarly with classes of products when you have those concepts, things they relate to, and so on. Most of the work is settling down on what those products are.
* SC: Example, we expect interop to be something between app that reads profile/TI docs, and a resource server making it available, if they can interact we accomplished interop. If we have ??? doing the reading/modifying, we don't claim that product needs to interact with a product that reads. Those two things don't need to interact. The app being able to read/write... the dirtect connection is between the thing creating a TI and a server, and the other one is the server requests from a writer. reader <> server, writer <> server. Those two things could be two different types of interop you can expect. Try to thing about those interactions. You probably need to hear from people, because at the same time someone can say "server is too big to implement. I just want to implement a resource/notification server, or just a processor". You need to figure out, work with the community to settle it.
* TT: It came across as intended and now VB and I will go do homework.  

### Feedback needed on Type Indexes

* VB Proposed by TT
* SC: The way I am reviewing, mostly focusing on readability/consistency, linking to things, etc. Tidying up. There are considerations I'm raising, you can look at it line by line or take as a whole and see how you can look at it to update. Up to you. Goes for every spec, I see a word and ask what meaning is... other readers will have similar thoughts.
* SC: I will finish reviewing it. And I will see how other things go.
